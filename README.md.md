# ğŸŒŸ AWS Data Lake Pipeline Project â€” Amazon Dataset  
A complete endâ€‘toâ€‘end AWS Data Lake implementation using **S3, Glue, Athena, Lake Formation, CloudWatch, and QuickSight**.

<p align="center">
  <img src="images/Architecture.png" width="700"/>
</p>

---

# ğŸ“˜ Table of Contents
- [ğŸš€ Project Overview](#-project-overview)
- [ğŸ“‚ Architecture Diagram](#-architecture-diagram)
- [ğŸ› ï¸ Step-by-Step Implementation](#ï¸-step-by-step-implementation)
- [ğŸ”’ Security & Governance](#-security--governance)
- [ğŸ“Š Visualization](#-visualization)
- [ğŸ§ª Testing, Monitoring & Optimization](#-testing-monitoring--optimization)
- [ğŸ¯ Outcomes](#-outcomes)

---

ğŸ‰ AWS Data Lake Pipeline Project - Amazon Dataset ğŸ‰
Welcome to the AWS Data Lake Pipeline Project! ğŸš€ This repository documents the end-to-end implementation of a data lake to ingest, catalog, transform, query, and secure an amazon.csv dataset using AWS services. Built from scratch on August 25, 2025, this project showcases a scalable solution for managing product data (e.g., category, rating). Letâ€™s explore the journey! ğŸŒŸ


![AWS Data Lake Architecture](images/Architecture.png)

ğŸŒŸ Overview of the Project
This project constructs a data pipeline to process and analyze an amazon.csv dataset containing product details. We utilized AWS services to:

ğŸ“¥ Ingest and Store: Load raw data into Amazon S3.
ğŸ“š Catalog: Generate metadata with AWS Glue.
ğŸ”§ Transform (ETL): Optimize data with Glue Jobs.
ğŸ“Š Query: Perform SQL queries using Amazon Athena.
ğŸ”’ Secure: Enforce access control with AWS Lake Formation.
ğŸ‘€ Monitor: Track operations with CloudWatch.

The pipeline is anchored around the S3 bucket analysis-data-lake-bucket-20250825, Glue database amazon_db, table amazon_csv, and the IAM role glue-etl-role (ARN: arn:aws:iam::747757438809:role/glue-etl-role). ğŸ¯

ğŸš€ Step-by-Step Implementation
Hereâ€™s a detailed log of the steps we executed to build this project:
1. ğŸ“¥ Preparation and Setup (Infrastructure Foundation)

Actions:
Signed into the AWS Console (console.aws.amazon.com) and selected region us-east-1. ğŸŒ
Created S3 bucket analysis-data-lake-bucket-20250825 with:
Block public access enabled. ğŸ”’
Server-side encryption (SSE-S3) activated. ğŸ”
Versioning enabled for data recovery. ğŸ”„
(Optional) Lifecycle rule planned for future optimization. â³
![S3-Buckets](images/S3-Buckets.png)



Created IAM role glue-etl-role with policies:
AWSGlueServiceRole for Glue access. ğŸ› ï¸
Custom S3 policy for analysis-data-lake-bucket-20250825. ğŸ“¦
AmazonAthenaFullAccess for querying. ğŸ“Š
Trust policy updated for glue.amazonaws.com and lakeformation.amazonaws.com. ğŸ”‘



(Optional) Set up VPC endpoints for S3 and Glue for private traffic. ğŸŒ


Outcome: Secure infrastructure foundation established. âœ…
![Glue-Role](images/Glue-Role.png)

2. ğŸ“¥ Data Ingestion (Getting Data into the Lake)

Actions:
Prepared amazon.csv with product data (e.g., category, rating). ğŸ“‹
Uploaded amazon.csv to s3://analysis-data-lake-bucket-20250825/raw/amazon/ via S3 console. ğŸ“¤
Organized S3 structure with raw/, refined/, and athena-results/ folders. ğŸ“‚

Outcome: Raw data ingested and stored durably in S3. âœ…
![Analyis Data Set and S3 Structure](images/Analysis-Report.png)

3. ğŸ“š Cataloging Data (Metadata Management)

Actions:
Created Glue database amazon_db in the Glue console. ğŸ“–
Configured crawler amazon-crawler to scan s3://analysis-data-lake-bucket-20250825/raw/amazon/:
IAM role: glue-etl-role. ğŸ”‘
Target database: amazon_db. ğŸ“š
Ran crawler to generate amazon_csv table with inferred schema. ğŸ•µï¸â€â™‚ï¸


Troubleshot TABLE_NOT_FOUND by re-verifying S3 data and re-running the crawler. ğŸ› ï¸


Outcome: Metadata cataloged, enabling queryability. âœ…
![Crawler](images/Crawler.png)

![DataCatalog Database and Table View](images/Table.png)



4. ğŸ”§ ETL (Extract, Transform, Load)

Actions:
Created Glue job amazon-etl-job with:
IAM role: glue-etl-role. ğŸ”§
Type: Spark (PySpark). âš¡
Workers: 2 DPUs. ğŸ’»
Output path: s3://analysis-data-lake-bucket-20250825/refined/amazon-parquet/. ğŸ“¦


Wrote and executed PySpark script:import sys
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
from pyspark.sql.functions import col

args = getResolvedOptions(sys.argv, ['JOB_NAME'])
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)

datasource = glueContext.create_dynamic_frame.from_catalog(database="amazon_db", table_name="amazon_csv")
transformed = datasource.toDF().na.drop(subset=["rating"]).withColumn("discount_percentage", col("discount_percentage").cast("float"))
aggregated = transformed.groupBy("category").agg({"rating": "avg"}).withColumnRenamed("avg(rating)", "avg_rating")
aggregated.write.mode("overwrite").partitionBy("category").parquet("s3://analysis-data-lake-bucket-20250825/refined/amazon-parquet/")

job.commit()


Ran the job and created a new crawler for refined/amazon-parquet/ to generate amazon_refined. ğŸ”„


Outcome: Transformed data optimized as Parquet with aggregated insights. âœ…

![ETL-JOB](images/etl-job.png)


5. ğŸ“Š Querying Data (Ad-Hoc Analysis)

Actions:
Created Athena workgroup amazon-workgroup via AWS CLI:aws athena create-work-group --name amazon-workgroup --configuration '{"ResultConfiguration": {"OutputLocation": "s3://analysis-data-lake-bucket-20250825/athena-results/"}, "ExecutionRole": "arn:aws:iam::747757438809:role/glue-etl-role", "EnforceWorkGroupConfiguration": true, "PublishCloudWatchMetricsEnabled": false}'


Set query result location to s3://analysis-data-lake-bucket-20250825/athena-results/. ğŸ“
Ran queries:
Raw: SELECT category, rating FROM amazon_csv WHERE rating > 4 ORDER BY rating DESC LIMIT 10;
Refined: SELECT category, avg_rating FROM amazon_refined ORDER BY avg_rating DESC;


Resolved TABLE_NOT_FOUND by re-running the crawler. ğŸ•’


Outcome: Successfully queried raw and refined data. âœ…
![Athena Query](images/AthenaQuery.png)


6. ğŸ”’ Security and Governance (Access Control)

Actions:
Set up Lake Formation:
Granted admin permissions to admin-analysis-team. ğŸ‘¤
Registered s3://analysis-data-lake-bucket-20250825/ with glue-etl-role. ğŸŒ
Enabled Lake Formation Mode. âš™ï¸


Applied permissions:
glue-etl-role: Describe, Alter on amazon_db, Select, Describe on amazon_csv (columns category, rating), and Data access on S3. ğŸ”
Revoked default IAMAllowedPrincipals permissions. ğŸš«




Outcome: Data lake secured with fine-grained access. âœ…
![LakeFormation](images/LakeFormation.png)
![AdminUser](images/AnalysisTeamUser.png)
![Adminstrative Roles and Tasks](images/AdminRolesAndTask.png)
![Colum-Based-Access](images/Column-Based-Access.png)
![Trust-Relationship-Glue-Role](images/Trust-Relationship-Glue-Role.png)


7. ğŸ‘€ Visualization and Insights (Reporting)

Actions:
Set up Amazon QuickSight:
Signed up for a free trial. ğŸ“Š
Granted access to S3 and Athena. ğŸ”‘


Created dataset and dashboard:
Source: amazon_db.amazon_refined.
Visual: Bar chart of category vs. avg_rating for top-rated products. ğŸ“ˆ
Published and shared the dashboard. ğŸŒ




Outcome: Visual insights generated (e.g., top-rated categories). âœ…
![QuickSight DashBoard - 1](images/QuickSight-1.png)
![QuickSight DashBoard - 2 ](images/QuickSight-2.png)

8. ğŸ” Testing, Monitoring, and Optimization

Actions:
Tested: Deleted a file in raw/, restored via versioning, and re-ran crawler/ETL/query. âœ…
Monitored: Set up CloudWatch metrics for Glue job duration and Athena data scanned. ğŸ“¡
Optimized: Used Parquet partitioning to reduce query costs. ğŸ’¡
Cleaned Up: Emptied/deleted S3 bucket, stopped Glue jobs, and deleted QuickSight resources. ğŸ§¹


Outcome: Reliable, optimized, and cost-effective pipeline. âœ…
![CloudWatch Monitoring](images/CloudWatch.png)


ğŸŒˆ Architecture Diagram
[External Data Source] --> [Amazon S3] --> [AWS Glue] --> [AWS Glue Jobs] --> [Amazon Athena] --> [AWS Lake Formation & CloudWatch]
    |                        |                |                    |                     |                        |
    +---- Raw Data --------->|------ Catalog -->|----- Transform ---->|------- Query ------->|----- Secure & Monitor -+
                             (amazon_db, amazon_csv)          (amazon_refined)           (category, rating)       (Permissions, Logs)


S3: Stores analysis-data-lake-bucket-20250825 with raw/, refined/, and athena-results/.
Glue: Manages amazon_db, amazon_csv, and amazon_refined via amazon-crawler and amazon-etl-job.
Athena: Queries with amazon-workgroup.
Lake Formation: Secures with admin-analysis-team and glue-etl-role.
CloudWatch: Monitors logs and metrics.


ğŸ¯ Project Outcomes

ğŸ“ˆ Built a fully functional data lake pipeline from scratch.
ğŸ”’ Implemented robust security with Lake Formation.
ğŸ“Š Enabled querying and visualization of key metrics.
ğŸš€ Optimized for scalability and cost efficiency.






---

## â­ Author  
**Mahesh Kumar S**

If you like this repository, donâ€™t forget to â­ star it!

---

